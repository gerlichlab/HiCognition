"""sprint9 sprint10 migration

Revision ID: 1018ea6830a5
Revises: 93912fdea0e2
Create Date: 2022-10-25 14:41:11.756029

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import mysql

# revision identifiers, used by Alembic.
revision = '1018ea6830a5'
down_revision = '93912fdea0e2'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('repository',
    sa.Column('name', sa.String(length=64), nullable=False),
    sa.Column('url', sa.String(length=512), nullable=True),
    sa.Column('file_url', sa.String(length=512), nullable=True),
    sa.Column('auth_required', sa.Boolean(), nullable=True),
    sa.PrimaryKeyConstraint('name')
    )
    op.create_table('repository_auth',
    sa.Column('user_id', sa.Integer(), nullable=False),
    sa.Column('repository_name', sa.String(length=64), nullable=False),
    sa.Column('key', sa.String(length=512), nullable=False),
    sa.Column('secret', sa.String(length=512), nullable=False),
    sa.ForeignKeyConstraint(['repository_name'], ['repository.name'], name='fk_repoauth_repo'),
    sa.ForeignKeyConstraint(['user_id'], ['user.id'], name='fk_repoauth_user'),
    sa.PrimaryKeyConstraint('user_id', 'repository_name')
    )
    
    op.add_column('dataset', sa.Column('metadata_json', sa.JSON(), nullable=True))
    op.add_column('dataset', sa.Column('repository_name', sa.String(length=64), nullable=True))
    op.add_column('dataset', sa.Column('sample_id', sa.String(length=128), nullable=True))
    op.add_column('dataset', sa.Column('source_url', sa.String(length=512), nullable=True))
    op.add_column('dataset', sa.Column('upload_state', sa.String(length=64), nullable=False))
    
    op.alter_column('dataset', 'dataset_name',
               existing_type=mysql.VARCHAR(length=512),
               nullable=False)
    op.alter_column('dataset', 'public',
               existing_type=mysql.TINYINT(display_width=1),
               nullable=False)
    op.alter_column('dataset', 'user_id',
               existing_type=mysql.INTEGER(),
               nullable=False)
    
    op.drop_index('ix_dataset_dataset_name', table_name='dataset')
    op.drop_index('ix_dataset_file_path', table_name='dataset')
    op.drop_index('ix_dataset_filetype', table_name='dataset')
    
    op.create_foreign_key('fk_dataset_repository', 'dataset', 'repository', ['repository_name'], ['name'])
    
    op.add_column('association_interval_data', sa.Column('job_status', sa.String(length=64), nullable=True))
    op.add_column('average_interval_data', sa.Column('job_status', sa.String(length=64), nullable=True))
    op.add_column('embedding_interval_data', sa.Column('job_status', sa.String(length=64), nullable=True))
    op.add_column('individual_interval_data', sa.Column('job_status', sa.String(length=64), nullable=True))
    op.add_column('individual_interval_data', sa.Column('value_type', sa.String(length=64), nullable=True))


def downgrade():

    op.drop_column('individual_interval_data', 'value_type')
    op.drop_column('individual_interval_data', 'job_status')
    op.drop_column('embedding_interval_data', 'job_status')
    op.drop_column('average_interval_data', 'job_status')
    op.drop_column('association_interval_data', 'job_status')
    
    op.drop_constraint('fk_dataset_repository', 'dataset', type_='foreignkey')
    
    op.create_index('ix_dataset_filetype', 'dataset', ['filetype'], unique=False)
    op.create_index('ix_dataset_file_path', 'dataset', ['file_path'], unique=False)
    op.create_index('ix_dataset_dataset_name', 'dataset', ['dataset_name'], unique=False)
    
    op.alter_column('dataset', 'user_id',
               existing_type=mysql.INTEGER(),
               nullable=True)
    op.alter_column('dataset', 'public',
               existing_type=mysql.TINYINT(display_width=1),
               nullable=True)
    op.alter_column('dataset', 'dataset_name',
               existing_type=mysql.VARCHAR(length=512),
               nullable=True)
    
    op.drop_column('dataset', 'upload_state')
    op.drop_column('dataset', 'source_url')
    op.drop_column('dataset', 'sample_id')
    op.drop_column('dataset', 'repository_name')
    op.drop_column('dataset', 'metadata_json')
    
    op.drop_table('repository_auth')
    op.drop_table('repository')
