[
{
	"uri": "http://localhost/docs/widgets/widget_controls/",
	"title": "Widget controls",
	"tags": [],
	"description": "",
	"content": "Widget collections and widgets have controls that allow resizing, zooming, and selecting hosted datasets. Widget collections always have the same set of controls. In contrast, widgets have additional, context-dependent controls that depend on the type of loaded widgets (see the description of widget types in this section).\nWidget Collection Widget collections represent genomic region sets and can host a variable number of widgets representing genomic features at this shared region set. Thus, the controls found on widget collections can change the selected region set and the arrangement of contained widgets.\nSelect genomic region set To select a genomic region set, click on the middle button at the top of a given widget collection:\nThis will cause the dataset selection dialogue to pop-up, where you can select a genomic region set for this widget collection:\nOnce selected, the name of the selected region set will be displayed on the blue horizontal bar at the top of the widget collection. Set window size If your region set is a point-features (see this section for a detailed explanation), the top controls of the widget collection will allow you to select the specific window size that all the widgets inside the collection display:\nThis means that with this selection, you can \u0026ldquo;zoom\u0026rdquo; in and out of your genomic region of interest to observe effect at different genomic scales.\nResize and delete widget collection You can resize the widget collection with all of its containing widgets using the controls at the top-left of the widget collection:\nNote that widget collections have a set minimum size beyond which you cannot shrink the widget collection.\n If you want to delete a widget collection, you can click on the garbage can at the top right.\nCreating slots Widget collections can contain multiple slots for widgets. These slots can be created by hitting the arrow buttons on the right and bottom of a widget collection. For example, you can click the arrow on the right to create an additional slot for a widget:\nCreating widgets To create a widget, you can hover over the central button inside the widget slot to reveal the widget selection menu:\nOnce you click on a specific widget, the slot gets filled with an empty widget of that type:\nArranging widgets Widgets can be dragged from one slot to another in order to create the perfect arrangements for your analysis question. For this, just drag the widget to your target slot:\nWidgets All widget types have their own \u0026ldquo;widget controls\u0026rdquo; described in the chapter of the respective widgets. In addition to that, all widgets share controls for selecting datasets, selecting bin size, and deleting widgets.\nSelecting genomic features To select a genomic feature for a given widget, click the button on the top right.\nThis will open the dataset selection table or the collection selection table depending on which data type is suitable for the current widget. Using this table, you can select which features you want to load into the given widget.\nChanging bin size To change the genomic resolution at which you want to look at the data, you can select the desired binsize from the binsize dropdown at the top of each widget.\nFor point features, binsize will be in genomic coordinates, whereas for interval features, binsize will be in the percentage of the respective region size. See this section for a more detailed explanation.\n "
},
{
	"uri": "http://localhost/docs/preprocessing/job_types/",
	"title": "Preprocessing tasks",
	"tags": [],
	"description": "",
	"content": "HiCognition provides a number of concrete preprocessing tasks that are related to the abstract tasks defined in the concepts section. These can be structured as tasks that aggregate genomic features for a given region set or tasks that aggregate collections of features. The preprocessing tasks are related to the types of widgets available for exploration, although some tasks produce data for multiple widgets.\nTasks for single genomic features These tasks aggregate a single genomic feature on a genomic region set and thus make this feature available for exploration.\nis aggregated feature -------------------\u0026gt; region-set Aggregate a 1D-feature at a genomic region set This task produces data for the 1D-average widget and the Stacked lineprofile widget and amounts to extracting the signal of a biwig file at a genomic region set (see the widgets section for a detailed description of the algorithm).\nAggregate a 2D-feature at a genomic region set This task produces data for the 2D-average widget and the 2D-feature embedding widget and amounts to extracting the signal of a multiresolution cooler file at a genomic region set (see the widgets section for a detailed description of the algorithm).\nTasks for collections of genomic features These tasks aggregate a collection of genomic features on a genomic region set and make this collection available for exploration.\nfeature1 --- | feature2 ---| is aggregated |------\u0026gt; Collection -------------------\u0026gt; region-set . | | featureN --- Aggregate a 1D-feature collection at a genomic region set This task produces data for the 1D-feature embedding widget and amounts to embedding the genomic region set using the 1D-features into a 2D-space (see the widgets section for a detailed description of the algorithm).\nAggregate a Region collection at a genomic region set This task produces data for the Association widget and amounts to running LOLA on the region set of interest with the region collection (see the widgets section for a detailed description of the algorithm).\nDuration of tasks A visual exploration tool is only useful if the tasks it fulfills can be completed in a reasonable time. Therefore, we have worked hard on minimizing the required time for each preprocessing step. If you use the default configurations and a machine that complies with our hardware requirements, none of the jobs should take longer than ~ 3 minutes. The following table gives a rough estimate of how long different preprocessing steps are expected to run for common input sizes.\n   Region size Preprocessing task Duration [min]     1000 Aggregate a 1D-feature at a genomic region set 0.1   1000 Aggregate a 2D-feature at a genomic region set 0.6 *   1000 Aggregate a 1D-feature collection at a genomic region set 0.5   1000 Aggregate a Region collection at a genomic region set 0.5   50000 Aggregate a 1D-feature at a genomic region se 0.5   50000 Aggregate a 2D-feature at a genomic region set 3 *   50000 Aggregate a 1D-feature collection at a genomic region set 2.5   50000 Aggregate a Region collection at a genomic region set 2.5    * For the Aggregate a 2D-feature at a genomic region set task, the first time you preprocess that particular region, you should expect that it runs ~2x as long as we calculate the Observed/expected values the first time and then cache them for future runs.\nIf you change the configuration for windowsizes and binsizes, the jobs may take much longer and require more memory.\n That being said, on-demand preprocessing is just one of the potential user flows. We think many preprocessing steps can be submitted in bulk as a large part of exploration tasks involve common \u0026ldquo;dataset ingredients\u0026rdquo;.\n"
},
{
	"uri": "http://localhost/docs/data_management/regions/",
	"title": "Regions",
	"tags": [],
	"description": "",
	"content": "Genomic regions are the central element of the region-set focus approach and are represented in practice by BED files that the user uploads to the server.\nData requirements BED-files should conform to the BED-standard, meaning that they should contain all required BED fields with tab-separated entries:\n chrom chromStart chromEnd  BED-files that are accepted by HiCognition may contain column names, so the following is acceptable:\nchrom start end chr1 1234 5678 . . . . . . . . . In addition, BED-files can contain comment lines (containing a leading #) as well as track and browser lines. So the following would be an acceptable file:\n# This is my favorite file track name=pairedReads description=\u0026#34;Clone Paired Reads\u0026#34; useScore=1 chr22 1000 5000 cloneA 960 + 1000 5000 0 2 567,488, 0,3512 chr22 2000 6000 cloneB 900 - 2000 6000 0 2 433,399, 0,3601 A requirement that you are responsible for yourself is that the BED-file conforms to the selected genome assembly (see the genome assemblies section for more information). HiCognition won\u0026rsquo;t crash when preprocessing using a BED-file with chromosomes, not in your selected genome assembly but will emit blank data for those regions. But we cannot check whether positions within the bounds of a given assembly are derived from that assembly!\nAlways check that your BED-file contains coordinates that fit the selected genome assembly!\n Types of genomic regions HiCognition supports two different types of genome regions that will be preprocessed and displayed differently. For a description of how the visualizations adapt to the different types of genomic regions, see the widget section.\nPoint regions HiCognition treats point regions as points in the genome. This means that internally, the start and end field in your uploaded BED-file will be collapsed into a single position that represents the center of that region. This region type is suitable when the features you look at likely have no internal structure through the span of your regions. Examples here are Chip-seq peaks of transcription factors, transcriptional start sites of genes, or boundaries of topologically associating domains.\nWhen working with point regions, HiCognition will create views with different window sizes around these point regions to allow exploration of multiple length scales.\nWindowsize Point Small -----|----- | | Point | --------------|-------------- | | Point | --------------------|-------------------- | v Point Large ----------------------------|---------------------------- To reduce computational load, the binsizes at which features are aggregated get smaller when windowsizes get larger. The particular setting can be changed in the configuration files of HiCognition (see the configuration section for more details).\nInterval regions HiCognition treats interval regions as regions that have a meaningful start, end and with that size in the genome. This region type is suitable when the features that you look at likely have internal structure through the span of your regions. Treating regions as interval regions is also useful when they have different sizes, and you want to look at features without regard for the region\u0026rsquo;s size. This is because all preprocessing steps for interval regions change the coordinate system from genomic coordinates to relative coordinates with relation to the size of the regions.\nThe binsizes that are used to aggregate features are thus defined as a percentage of the interval size. Practically, this means that if you have a particular region that is 1 Mbp in size and another region that is 500 kbp in size, the effective binsize (at 1 %) for the former will be 10 kbp and for the latter 5 kbp. This also means that we interpolate genomic features to fit the target binsize. This is convenient to exclude size effects but can introduce artifacts. So always have that in mind when exploring interval features!\nInterval regions will cause genomic features to be scaled to a common size. This can introduce artifacts!\n Interval regions are displayed with a little expansion left and right to be able to compare them to a potential baseline:\nLeft Expansion Region Right Expansion ---------------|---------------------------------|--------------- See the configuration section for how to set the extent of the expansion.\nDescription of genomic regions To allow efficient filtering and searching as well as an easier display of genomic regions, we defined a formal description of genomic region sets that is exposed to the user both when adding new regions and when viewing genomic regions. The structure of the description fields of a genomic region set can be seen in the following graph:\nIn this graph, all nodes representing a value that the user can select are red. If the user\u0026rsquo;s selection can lead to different selections lower in the graph, these options are displayed as black nodes. The first children of Region are fields that need to be defined for all region sets and have no influence on the later selection hierarchy:\n Assembly | The genome assembly this region set belongs to Perturbation | The perturbation condition (or none) that was used in the experiment that led to this dataset CellCycleStage | The cell cycle stage the cells were in when the data was collected SizeType | Which sizetype (see above) the genomic regions should be treated as  Then, the ValueType needs to be selected. This describes what kind of genomic regions this dataset is. This can be one of the following:\n Peak | A peak from an experiment that produces continuous genomic data e.g., ChiP-Seq GenomeAnnotation | A genomic region set that is obtained by integrating multiple data sources and human intervention (e.g., genes, transcriptional start sites, etc.) Derived | If regions have been derived from a single other dataset (e.g., TADs derived from a Hi-C experiment)  Selection of a specific ValueType leads to different required metadata downstream. E.g., if the ValueType is Peak than the possible selection of methods is different than when the ValueType is Derived.\nAdding genomic regions Adding genomic regions can be done by uploading a BED-file and filling out the required metadata field. This can be done for single files or with multiple files using the bulk addition option.\nSingle addition To add a single genomic region set, open the side drawer and click on the add region button:\nThen, a dialog will pop up where you can select a region file, specify its name and select a genome assembly.\nWhen you added the BED-file, options will appear that encapsulate the hierarchical structure describe above\nOnce you are happy with your selection, you can hit submit, and your dataset will be uploaded!\nBulk addition If you want to add multiple genomic regions, you can use the bulk addition option:\nBulk addition is organized as a stepper, where you add the same information as in the single addition at the different positions of the stepper.\nManaging genomic regions Managing genomic regions is done using a central table component that can be opened in the data management sidebar:\nViewing When you click on the Show Regions button, a table dialogue opens that shows you all available genomic region sets:\nThis top-row of this view allows you to select a specific genome assembly and contains a search field that allows for quick filtering of interesting datasets. For more fine-grained control over the filtering process, you can expand the filter box, which displays the description fields mentioned above.\nPer default, only a subset of fields are displayed, but you change this in the fields box:\nAll interfaces in HiCognition that need dataset selection are using this table component.\nEditing You can edit the description fields and name of a dataset by selecting it in the table component and then hitting the Edit button. This will display the edit dialogue:\nHere you can edit most description fields, and once you are finished, you can hit Submit Dataset to save your changes.\nThe only parameter you cannot edit is the SizeType field, which would invalidate prior preprocessing on the dataset.\n Deleting You can delete datasets by selecting them in the table component and then hitting the Delete button. Note that you can only delete a dataset when you are its owner, not when it has been shared (see the dataset sharing section for more information) with you.\nDeleting a dataset will cause all preprocessing data to be lost. Be careful!\n "
},
{
	"uri": "http://localhost/docs/concepts/background/",
	"title": "Background",
	"tags": [],
	"description": "",
	"content": "Genomic data exploration The advent of high throughput sequencing has not only enabled researchers to assemble a multitude of different genomes but also firmly established sequencing-based readouts as tools to quantify genome function. This capability has sparked the ENCODE project (Encyclopedia of DNA Elements) that aims to segment genomes into discrete functional units such as genes, insulators, and enhancers based on an extensive catalog of quantitative genomics datasets. Through this and other resources, researchers can draw upon a wealth of genome annotations and integrate them with their own datasets. This approach has become particularly important in spatial genomics, where researchers aim to understand determinants of the 3D structure of genomes by relating conformation capture datasets with genome annotations and quantitative genomics datasets. This task is particularly difficult because it requires the relation of a high-dimensional and variable readout with many potentially associated datasets. Thus, researchers often resort to an initial visual exploration phase to narrow down potential associations.\nGenome browsers are amongst the most prominent tools used for this task and allow non-programmers to quickly explore multidimensional datasets by relating genomic tracks to each other and offer the capability to manage genomic datasets. These tools, however, only allow exploration of a limited set of views and thus make it challenging to visualize behavior at multiple related genomic regions. More specialized tools have been developed recently to partially solve this problem, namely HiPiler as a standalone GUI and Piling.js as a javascript framework. These tools allow manipulation and aggregation of a small set of 1D- or 2D genomic regions via the concept of a visual pile. While these tools have introduced important visual concepts, there are practical challenges when analyzing real-world genomic data, where sets of regions of interest routinely surpass 50,000 entries.\nFig. 1\nGenomic analysis cycle: The status-quo Following this initial data exploration phase, quantitative analysis of genomic datasets is carried out using frameworks in scripting languages. This is done either by programming directly or via integration into tools that allow automatic dispatch, such as galaxy. These tools offer a wide range of functionality and flexibility, which comes at the cost of slow exploration since one needs to write custom code for each new exploration idea.\nThus, the task of relating genomic function to 3D structure often follows an implicit analysis cycle (Fig. 1a). First, researchers use track-based exploration to get an overview of the genomic datasets available for their particular problem. Here, multiple genomic tracks (continuous or discrete values mapped to genomic coordinates) are viewed together in a suitable genome browser and explored by panning and zooming. Researchers then need to integrate knowledge of the biological problem with multiple explored tracks to formulate hypotheses about the aggregate behavior of data (data hypotheses). These hypotheses are then tested by aggregate analysis using scripting languages, leading to re-assessment of the genomic tracks and formulation of refined data hypotheses.\nDrawbacks of this approach Interface between exploration and analysis This approach of analyzing genomic data presents multiple problems (Fig. 1b). First, separating the exploration of genomic data from testing data hypotheses creates an interface that needs to be bridged. Here, analysts need to switch analysis tools to perform both tasks, increasing the threshold of testing data hypotheses and prolonging the required analysis time. This is a particular problem when biologists with limited scripting experience perform track-based exploration. In that case, they need to rely on a bioinformatician to complete their data hypothesis testing, incurring long wait times and communication overheads.\nQuality of hypotheses The second problem using track-based exploration is that the quality of possible data hypotheses is likely limited. This is partly because simultaneous viewing of multiple genomic tracks is akin to finding patterns in a multidimensional dataset, a task that humans are notoriously bad at. Additionally, track-based exploration only allows viewing of a limited number of associations simultaneously, posing the danger of missing rare associations and proposing spurious ones. Thus, track-based exploration is not an ideal analysis approach for multidimensional genomic data.\nLast but not least, a well-established principle that any visual system should follow is Schneiderman\u0026rsquo;s mantra: overview first, zoom and filter, then details-on-demand. However, a track-based system is ill-suited to give an overview since, per definition, it focuses on the details of a single region. It mainly helps us detect anomalies but can not give us an overview or explicitly display its properties and pattern on a system-wide level.\nHiCognition can help solve these problems In order to overcome this problem, we conceptualized the region-set focus approach and implemented it in HiCognition.\n"
},
{
	"uri": "http://localhost/docs/installation/requirements/",
	"title": "Requirements",
	"tags": [],
	"description": "",
	"content": "Software The only software requirement for HiCognition is docker. To install Docker, follow the respective installation guide for your platform. All needed containers are specified in the docker-compose file in the HiCognition repository (see build for more details).\nHardware HiCognition is an integrated data exploration and preprocessing platform. This means that it is not only responsible for displaying visualizations but also provides a preprocessing queue (see preprocessing for more details) to calculate aggregation data of large genomic data sets. Thus, the server running HiCognition needs to be sufficiently powerful to allow these preprocessing steps. While the number of parallel worker processes for preprocessing and the maximum genomic resolution can be specified in the server configuration (see configuration for more details), we recommend using a server with the following minimum specifications:\n   Number of simultaneous users CPU Memory Disk space     5 4 cores 8 Gb 100 Gb   10 16 cores 32 Gb 200 Gb   20 32 cores 64 Gb 400 Gb    It is somewhat difficult to estimate how to derive the number of simultaneous users from the total numbers of users. Therefore, we recommend monitoring resource usage closely when initially setting up HiCognition.\n"
},
{
	"uri": "http://localhost/docs/getting_started/",
	"title": "Getting started",
	"tags": [],
	"description": "",
	"content": "Getting started This section assumes that you have a HiCognition instance running and set up your user in the database. On how to do this, see the installation guide.\n Get started with example data Start creating your first visualizations with our example data.\n"
},
{
	"uri": "http://localhost/docs/development/development_info/",
	"title": "App architecture",
	"tags": ["development", "architecture"],
	"description": "",
	"content": "This document contains a description of the architecture of HiCognition, which can be summarized in the following scheme:\nBack-end Docker network All the docker containers that work together in the back-end are coordinated by docker-compose (see docker-compose file) and reside within a docker-network called hicognition-net, to facilitate networking between them. The docker containers that are used are the following:\n hicognition - Container that harbors the flask-server mysql - contains Mysql database nginx - contains nginx reverse-proxy redis-server - contains the redis-server redis-worker - redis-worker container  Additionally, there is a transient container used:\n node - Node container that is started to build the front-end files  Flask-server The core of our back-end is a flask-server that runs in a custom docker container and manages the authorization of users and exchange of data with the Vue.js front-end. This flask-server is a pure REST-API, meaning that it is mostly state-less with regards to the user requests and serves data in JSON format. The API-routes are implemented using the blueprint-pattern to allow modularization and easy extension in the future.\nThe User-authorization is done either by sending the user credentials (username and password) or via a token that can be obtained from the /tokens/ route. The token is generated using itsdangerous.TimedJSONWebSignatureSerializer and is currently valid for 1h. The /tokens/ route only accepts username/password authorization to prevent malicious actors from obtaining new tokens with an old token indefinitely.\nDifferent configurations of the server are collected in a config.py file that defines classes that carry the configuration options as class variables. These different classes are used in the create_app app-factory function to register the relevant config settings via app.config.from_object(). The relevant config class can be specified via the env-variable FLASK_CONFIG. The different classes are:\n DevelopmentConfig - This configuration class is used in the development and specifies that flask should be started in development mode. TestingConfig - This configuration class is used during testing and creates a sqlite database in memory. ProductionConfig - This configuration class is used in production and specifies that the database should be created in the app directory resides in a file. End2EndConfig - This configuration class specifies the configurations for end2end integration testing  The general policy is to provide default values for development but get the values from environment variables in production. This is achieved by using the following pattern for each config-variable: Config = os.environ.get(\u0026quot;ENV_VAR\u0026quot;) or default. For a detailed description of the configuration variables see the configuration section.\nDatabase The flask-server and the Redis-queue worker use a common database to record and change information about users and datasets. We use SQLAlchemy as an Object-relational-mapper (ORM) to abstract details of the underlying database. This allows, in principle, to quickly change database back-ends and allows interaction with the database via python classes and functions. Currently, we use MySQL to store meta-information about datasets (file-path, name, etc.) and users directly in the database, and large data (images, raw-files, processed-files, etc.) is stored on the filesystem.\nDatabase migrations are managed using FLASK-Migrate that is a wrapper for alembic, a database migration tool for SQLAlchemy. Using this set-up, database migrations are scheduled using:\nflask db migrate -m $MESSAGE This creates a migration script in the ./migrations sub-folder. This migration can then be applied using flask db upgrade. The ./migrations directory is committed to version control and records the migration history of our database. The development workflow is to define database models in a models.py file and commit a migration to version control. Then, on the production server, the newest changes - including the migration script - are pulled, and the database migrated to the newest version using flask db upgrade.\nInteractions with the database are managed by FLASK-SQLAlchemy, which uses a ScopedSession object as db throughout the app, that ensures thread-safety of database interactions.\nDatabase model Details are here, this is an overview drawn using https://dbdiagram.io/home:\nFilesystem interactions The flask-server and the Redis-worker need access to a shared filesystem since all raw and processed datasets are stored as files, with their filenames being recorded in the database.\nQueue Resource heavy and long tasks are offloaded to a redis-queue that consists of a Redis-server and one or more Redis-workers. The Redis-server accepts task items and manages to distribute them to the Redis-workers. The Redis-server runs in a docker container that is derived from redis:6-alpine with a custom config-file. The Redis-workers use the same docker-container as the flask-server as they need access to most modules the server needs.\nAll tasks that the queue can run are defined in tasks.py.\nTasks are launched using an instance-method of User called User.launch_task that accepts the name of the task, a short description as well as the dataset_id of the dataset being processed. This method enqueues the job and adds the Task table entry to the current database session.\nThere are three different queues:\n short medium long  The tasks are distributed to these queues based on the PIPELINE_QUEUES configuration parameter (see the configuration section for more details)\nFront-end We use vue.js in the front-end to manage routing, interactivity and fetching data from the back-end. Here, we employ a template-based design, where each vue-component resides in its own .vue file that is included in the distribution built by webpack.\nBuild Front-end files (index.html, app.js, vendor.js, app.css, manifest.js) are built using webpack with configs set in frontend/build/build.js and frontend/build/webpack.prod.conf.js and frontend/build/webpack.dev.conf.js (these both use frontend/build/webpack.base.conf.js).\nBabel is first used to transpile js-files to support all browsers with \u0026gt; 1% market share and support the last 2 versions (config settings \u0026quot;browsers\u0026quot;: [\u0026quot;\u0026gt; 1%\u0026quot;, \u0026quot;last 2 versions\u0026quot;, \u0026quot;not ie \u0026lt;= 8\u0026quot;]). Then, js-files are minified and both js- and css-files are included in the generated index.html file and copied to the ./dist directory.\nEnvironment variables for development and production are defined using frontend/config/dev.env.js and frontend/config/prod.env.js, respectively. Variables are:\n API_URL - The URL of the flask-API STATIC_URL - The URL of the static directory. VERSION - The Version of HiCognition NOTIFICATION_URL - The URL of the notification stream  These variables are accessed in js-files using process.env.VARIABLE and resolved by webpack during the build.\nModules for build are imported using the \u0026ldquo;import\u0026rdquo;-syntax rather than the \u0026ldquo;require\u0026rdquo;-syntax (more info). This allows webpack to only bundle the actually used parts of a module, making the bundle smaller.\nDevelopment server A webpack development server is started using webpack-dev-server --inline --progress --config build/webpack.dev.conf.js --host 0.0.0.0 with the alias npm run dev. This enables hot-reload, real-time linting and the usage of front-end debugging using the vue-development chrome extension.\nVue set-up Vue is used to create a single-page application (SPA) in the front end. This requires the usage of several extensions that serve different parts of the app:\n vue-router - This manages front-end routing and enables route-nesting and routing of subsets of the current view vuex - Since a vue.js app often consists of multiple components and multiple routes, it is frequently necessary to share data between these parts. Vuex serves the purpose of a front-end database that allows sharing of data. vuematerial - Collection of components that facilitate development by encapsulating high-level user interfaces such as cards, buttons, etc.  Vue-router The specifics of the router are defined in frontend/src/router.js. In general, there are two main views called /login and /main. /login defines the loginRoute component that has a different toolbar to the /main view components. /main is where the app resides, and it contains one sub-route: /main/compare.\nThe /login route defines a form that sends the user credentials to the /api/token/ back-end route to obtain a token that is valid for 24 h.\nAll routes that are children of /main require authentication. Authentication is checked by verifying that a token resides in the main vuex store. If no token is found, the user is redirected to /login.\nNote that this routing step does not check the validity of the token. Validity is only checked when data is retrieved from the back-end.\n Vuex-Store Data that needs to be shared among multiple front-end components is stored in a vuex-store. This store is defined in frontend/src/store.js. There is a global store that stores data that needs to be accessible across the entire app (such as the authentication token and all available datasets). Additionally, there is a sub-store (called \u0026ldquo;modules\u0026rdquo; in vuex) for all data that needs to be shared among components in the /main/compare route. This has the advantage that local data such as dataset selections for a given view do not need to be stored in the global store, which avoids clumsy naming of variables.\nInteraction with back-end All interactions with the back-end are done via API calls that are dispatched by axios. The axios instance is bound to Vue.prototype.$http so all Vue instances and components have access to the client without import.\nThe API-calls are defined as a mixin in frontend/src/mixins.js in apiMixin. All components that need interaction with the back-end receive the apiMixin. The apimixin has a convenience method for fetching and storing the authentication token called .fetchAndStoreToken and two more generic methods that allow to dispatch, get and post requests, .fetchData and .postData, respectively. These work by returning the promise the is returned by Axios-requests is there is no error in the call. The caller can then resolve the promise and receive the data. If there is an error, however, the user is redirected to the login page to get a new token.\n"
},
{
	"uri": "http://localhost/docs/preprocessing/manage_preprocessing/",
	"title": "Manage preprocessing",
	"tags": [],
	"description": "",
	"content": "HiCognition provides a user interface to submit preprocessing tasks and check their progress.\nSubmit tasks Depending on whether you want to submit a task for features or collections (see here for more details), click either Preprocess Features or Preprocess Collections in the data management drawer:\nThis will open the preprocessing dialogue:\nHere, you first need to select for which region you want to start preprocessing. To do this, click on the Select region button. This will open up the dataset management table and allow you to select a genomic region:\nOnce you select the region, the Select Features/Select Collections button becomes available. If you click on it, this will again open either the dataset management table or the collection management table. Here, you can then select which features/collections should be preprocessed. Once you hit Select, the dialogue disappears, and you can hit the Submit Job button, which will cause preprocessing to be started.\nCurrently, there is a one-to-one mapping between preprocessing tasks and types of datasets. E.g., there is only one possible task for a 2D feature. Therefore, the preprocessing dialogue does not require the selection of the task type. In the future, this might change, and the dialogue will become more complex.\n Check tasks Once your tasks are running, you can check their progress via the dataset management table. If you open up the table, you can see two fields that are called Processing Features and Processing Collections. These indicate at a glance how many genomic features and feature collections are being processed for a given genomic region set. If you click on the columns, you can sort the table by this field and quickly see which datasets are processing:\nIf you want more information about task progress and also view which features and collections are available for a given genomic region set, you can click on the processing feature number and inspect the pop-up dialogue:\nThis table shows an additional status column that indicates whether a feature is currently processing, is already available, or has not been processed yet:\n   Icon Meaning      This icon means that this particular feature is currently processing    This icon means that this particular feature has finished processing and is available    This icon means that the feature has been uploaded and is available, but has not been preprocessed    Notifications When your preprocessing jobs finish, you will receive notifications. These are visible at the right side of the top toolbar:\nIf you click on the notification symbol, a side-drawer opens, where you can see that features finished preprocessing for which genomic region set:\nIf you click on the envelope symbol, you can acknowledge the notifications and mark them as read.\nWe don\u0026rsquo;t persist notifications in the database, so notifications are only visible in one viewing session. So, if you reload the browser or log out, the notifications will not be visible anymore.\n "
},
{
	"uri": "http://localhost/docs/data_management/features/",
	"title": "Features",
	"tags": [],
	"description": "",
	"content": "Genomic features are an essential part of the region-set focus approach and are defined as 1D- or 2D-continuous data that is mapped to a genomic coordinate system. Examples are ChiP-seq read density, Hi-C interaction values, and GRO-seq tracks. Genomic features are mainly used to understand genomic regions in the context of the region-set focus approach. They can thus be thought of as \u0026ldquo;independent variables\u0026rdquo; that are used to explain the \u0026ldquo;dependent\u0026rdquo; genomic regions.\nData requirements Bigwig files (1D-features) Bigwig files should conform to the Bigwig-standard, which translates to being readable by bigwig interface libraries (in our case, this is pybbi). In addition, your bigwig file should contain data that were aligned against the selected genome assembly. But as for BED-files, this is a requirement we can only check to a limited degree.\nAlways check that your bigwig file was derived from data that were aligned against the selected genome assembly!\n Multiresolution Cooler files (2D-features) HiCognition can load 2D-genomic features from multiresolution cooler files. Here, they same cautionary notes with respect to genome assemblies apply. In addition, mcool files need to contain the resolutions defined in the flask configuration file. For the default setting these are:\n 5000 10000 20000  Note that we consciously don\u0026rsquo;t try to search for the nearest fitting resolution as this would compromise comparability between genomic features. If you need a primer on how to create mcool files and what strategies for data normalization are available, see the cooler documentation.\nAlways check that your cooler file is compatible with the defined resolution restrictions!\n Description of genomic features To allow efficient filtering and searching as well as an easier display of genomic features, we defined a formal description that is exposed to the user when adding and viewing genomic features.\n1D-features The structure of the description fields for 1D features can be seen in the following graph:\nIn this graph, all nodes representing a value that the user can select are red. If the user\u0026rsquo;s selection can lead to different selections lower in the graph, these options are displayed as black nodes. The first children of Feature1D are fields that need to be defined for all region sets and have no influence on the later selection hierarchy:\n Assembly | The genome assembly this feature set belongs to Perturbation | The perturbation condition (or none) that was used in the experiment that led to this dataset CellCycleStage | The cell cycle stage the cells were in when the data was collected  Then, the ValueType needs to be selected. This describes what kind of genomic feature this dataset are. This can be one of the following:\n ProteinBinding | A dataset that represents that binding of a protein (e.g., derived from Chip-seq or CutandRun) GeneExpression | A dataset that represents gene expression (e.g., derived from GRO-seq) Derived | A dataset that was derived from another dataset (e.g., insulation score in Hi-C)  Selection of a specific ValueType leads to different required metadata downstream. E.g., if the ValueType is ProteinBinding, then the Protein field needs to be filled out.\n2D-features The structure of the description fields for 2D features can be seen in the following graph:\nIn this graph, all nodes representing a value that the user can select are red. If the user\u0026rsquo;s selection can lead to different selections lower in the graph, these options are displayed as black nodes. The first children of Featur2D are fields that need to be defined for all region sets and have no influence on the later selection hierarchy:\n Assembly | The genome assembly this feature set belongs to Perturbation | The perturbation condition (or none) that was used in the experiment that led to this dataset CellCycleStage | The cell cycle stage the cells were in when the data was collected  2D features currently only define a single ValueType:\n Interaction | A dataset that contains a quantification of genome interactions  Thus, the other fields are determined when uploading a 2D-feature dataset.\nAdding genomic features The addition of genomic features can be started by clicking on the Add genomic features button in the data management drawer:\nThis will open a dialogue that follows the same principles as the dialogue described for addition of genomic regions.\nGenomic features are typically much larger in size than genomic regions. This will cause the upload to take longer!\n Managing genomic features Managing genomic features is equivalent to managing genomic regions, except that the table component is launched from a different menu button:\n"
},
{
	"uri": "http://localhost/docs/widgets/lineprofile/",
	"title": "1D-average",
	"tags": ["widgets", "1D-features"],
	"description": "",
	"content": "The 1D-average widget can be used to display the average magnitude of a 1D-genomic feature over a specific region set. It is a simple line-profile visualization that can load one or more genomic datasets and implements a simple tooltip that shows the magnitude of the specific data sets.\nSuitable data The 1D-average widget is suitable for any genomic dataset that can be represented using a bigwig file. This includes coverage tracks for Chip-seq experiments, Gro-seq experiments, and features derived from Hi-C data, such as insulation scores.\nPreprocessing algorithm Point-regions Snippets are extracted from the respective bigwig file for each entry in the genomic region set, with different window sizes during the preprocessing stage. These snippets are stacked row-wise into a matrix and reduced column-wise to produce a single value per bin.\nInterval-regions Snippets are extracted from the respective bigwig file for each entry in the genomic region set during the preprocessing stage. In contrast to the point-region preprocessing, the snippets are defined by each region\u0026rsquo;s start and end. Before stacking, each snippet is scaled to have the same number of bins. Then they are stacked row-wise into a matrix and reduced column-wise to produce a single value per bin.\nVisualization The 1D-average widget displays aggregated data sets as a line profile, which plots the specific value for a genomic bin against its relative position with regards to the center. If you hover over the widget, a tooltip is displayed that reads the magnitude of the respective lines.\nWidget controls The 1D-average widget has a single widget control option - called Scale - which allows users to normalize the displayed data to lie between 0 and 1. This is helpful when comparing multiple features.\n"
},
{
	"uri": "http://localhost/docs/concepts/region_set_focus/",
	"title": "Region-set focus approach",
	"tags": [],
	"description": "",
	"content": "Region-set focus approach The idea behind the region-set focus approach is that there is a central region-set of particular interest in many biological questions. In contrast, other genomic data is mainly used to find associations. Specifically, a region-set of interest often arises either because the broad biological question gives a natural constraint (e.g., genes/enhancers in the gene expression field), or a particular experimental procedure produces a new region-set that is not characterized, for example, the set of expressed genes or changed 3d-genome interaction patterns in a perturbation condition. Many analysis questions associated with these region-sets of interest can be abstracted into a small number of tasks that are either associated with testing a specific hypothesis or with generating new hypotheses:\n Exploring average behavior: What is the average magnitude of a specific 1d-/2d-genomic signal? Exploring heterogeneity: Is the population of regions homogeneous with respect to a collection of 1d- or 2d-features? What subsets have different behavior with respect to a collection of 1d- or 2d-features? Enrichment analysis: What other regions are enriched?  With an explicit focus on region-sets of interest, these tasks can be formalized to the degree that allows automated precomputation. Here, the user selects a particular region-set and maps genomic features to them by submitting a precomputation job. The particular pre-computation job is dependent on the type of task and the type of genomic feature, where genomic features can either be continuous 1d- or 2d-signals along the genome (for example, a ChIP-seq signal of a particular protein), discrete signals along the genome (for example the binding sites of a protein of interest) or a collection of the above (e.g., the binding sites of chromatin modifiers). The results of these pre-computations can then be explored using visualization concepts tailored to the feature type.\nAn implementation of the region-set focus approach would allow users to complement implicit exploration of genomic features in a track-based browser with explicit analyses separated into the tasks mentioned above. Testing a specific hypothesis would allow robust evaluation of average behavior since appropriate pre-computation and visualization tools can be employed. When generating new hypotheses about the data, specialized visualization concepts can help find robust and complex associations that lead to better hypotheses. Additionally, making these analyses explicit allows storing user sessions and sharing them with collaborators, thereby fostering scientific exchange.\n"
},
{
	"uri": "http://localhost/docs/development/dev_env/",
	"title": "Development environment",
	"tags": ["development"],
	"description": "",
	"content": "Starting HiCognition in development mode We provide a docker-compose file that sets up the local development environment. This file uses the same containers as the production compose file, so if you haven\u0026rsquo;t done so, follow the instructions for building the containers.\nWhen you start a development HiCognition instance, the front-end files will be served by a node.js development server with enabled hot reload. You can then also use the Vue.js devtools Chrome extension for debugging. The back-end server that is started in the development instance is a flask development server, also with hot reload.\nTo get information about how to configure the environment variables for the development instance, see the configuration chapter.\nThe production HiCognition container copies the server code into the container during the build process and runs the server from there. In contrast, the development setup mounts the local code repository into the container to enable fast editing and hot-reload.\n You can start the development instance with the following command inside the cloned HiCognition repository:\ndocker-compose -f docker_dev.yml up After that, the app is available on http://localhost:8080\nGet shell access to the server To get access to the HiCognition flask server to run tests or interact with the MySQL database through our database models, attach a shell to the flask-server container. This can be done with the following command:\ndocker exec -it flask-server bash Once you have the shell inside the container, you have access to the command line convenience methods that allow quick interactions with the database. You can, for example, get a python shell with the database models loaded using:\nflask shell Additionally, you can add new users using the flask user define subcommand:\n Usage: flask user define [OPTIONS] NAME\nCreates a new user either with a defined password or password prompt. If user with the name exists already, the password is redefined.\nOptions:\n-p, \u0026ndash;password TEXT\n\u0026ndash;help Show this message and exit.\n An example workflow for creating a dummy user with an unsafe password is:\ndocker exec -it flask-server bash flask user define dummy -p 1234 To add datasets, you can use the flask dataset add command:\n Usage: flask dataset add [OPTIONS] JSON_PATH USER PASSWORD\nAdds datasets defined in a JSON to database and uploads it.\nOptions:\n\u0026ndash;help Show this message and exit.\n For bulk upload of data, you can also use our hicognition cli tool! TODO\n "
},
{
	"uri": "http://localhost/docs/installation/build/",
	"title": "Build",
	"tags": [],
	"description": "",
	"content": "Clone repository To get started, first clone the HiCognition GitHub repository:\ngit clone https://github.com/gerlichlab/HiCognition Build docker images HiCognition consists of multiple docker images that work together to power the app. The needed images are specified in the docker-compose.yml configuration file contained in the Github repository. Once you have cloned the repository, you can build the required images as follows:\ncd HiCognition # The location that has the cloned GitHub repository docker-compose build This step will pull multiple large base images and start the build process for HiCognition custom images. This step is expected to take roughly 20 minutes.\nStart HiCognition After the build process is finished, you can start up a HiCognition instance using the following command:\ncd HiCognition # The location that has the cloned GitHub repository docker-compose up -d The -d flag specifies that docker-compose should run in the background. The docker-compose configuration starts all components and builds the files for the front-end part of HiCognition. This is expected to take roughly 1 minute. After that, HiCognition is available on port 80 on your local machine!\nThe HiCognition repository contains an example environment file that specifies all the needed environment variables. You must change these to ensure that you use non-public passwords and secrets! See the configuration section for details.\n "
},
{
	"uri": "http://localhost/docs/concepts/",
	"title": "Concepts",
	"tags": [],
	"description": "",
	"content": "Concepts This section discusses why we think HiCognition is a good idea and present the concepts behind the app.\nBackground This section briefly looks at the existing status quo for genomic data exploration. We briefly introduce the drawbacks of the genomic analysis cycle and postulate how HiCognition aims to bridge the gap.\nRegion-set focus approach This section introduces a core novelty of HiCognition, the region-set focus approach and the key difference of HiCognition to classical genomic browser approaches.\nImplementation This section briefly touches on how we solved multiple problems that arise during genomic data exploration.\n"
},
{
	"uri": "http://localhost/docs/data_management/collections/",
	"title": "Collections",
	"tags": [],
	"description": "",
	"content": "HiCognition uses collections to group datasets together for them to be available for some of the more complex processing algorithms.\nCollection types There are two types of collections in HiCognition, which are defined by the types of datasets they contain.\n1D-feature collections 1D-feature collections are named groups of 1D-features, which can be used for preprocessing data for display in the 1D-feature embedding widget\nRegion collections Region collections are named groups of genomic regions, which can be used for preprocessing data for display in the Association widget\nCreating collections Creating collections can be done by first clicking the Create Dataset Collection button in the data management drawer:\nThis causes a dialogue to pop up:\nDatasets can be selected via the Select Datasets button that causes the dataset table component to appear. There, you can select which datasets your collection should contain. You can then give the collection a name and hit Submit Collection to create the collection.\nManaging collections To view your collections, you can hit the Show Dataset Collections button in the data management drawer:\nThis will cause a dialogue to appear that lets you look at all your dataset collections:\nThis table is similar to the table that allows viewing datasets except that it does not allow filtering based on descriptions (because collections have no description) and that the number of available fields is much lower. If you want to view which datasets are contained in a collection, you need to click on the number of contained datasets:\nThis will cause a dialogue to pop up that allows you to view the contained datasets:\nIf you want to delete a collection, select it and then click the Delete button.\n"
},
{
	"uri": "http://localhost/docs/widgets/2d_average/",
	"title": "2D-average",
	"tags": ["widgets", "2D-features"],
	"description": "",
	"content": "The 2D-average widget can be used to display the average magnitude of a 2D-genomic feature over a specific region set. It is a heatmap representation of the underlying aggregated data.\nSuitable data The 2D-average widget is suitable for any genomic dataset that can be represented using a multiresolution cooler file. This is primarily suitable for Hi-C data but can also include other data sets that assign a value to a tuple of genomic coordinates.\nPreprocessing algorithm Point-regions During the preprocessing state, snippets of the underlying interaction matrix are extracted from the mcool file for each entry in the genomic region set, with different window sizes. These snippets are then stacked \u0026ldquo;behind\u0026rdquo; each other and reduced pixel-wise to yield an average 2D picture.\nInterval-regions During the preprocessing stage, snippets of the underlying interaction matrix are extracted for each entry in the genomic region set. In contrast to the point-region preprocessing, the snippets are defined by each region\u0026rsquo;s start and end. Since the matrices are then of differing size, they are first scaled to a common number of bins before stacking and pixel-wise reduction.\nVisualization The 2D-average widget displays aggregated data sets as a heatmap. The color scale used to display the values is dynamic and can be adjusted with the sliders at the top and bottom of the color bar.\nWidget controls The 2D-average widget defines two widget controls, one for setting the type of value-scale and the other for sharing value scales between widgets.\nScale The scale widget control allows to switch between ICCF values (I teratively C orrected C ontact F requency) and Observer/expected values, which were normalized to the genome-wide distance-dependent decay of contact frequency.\nShare value scale With the share value scale control, the value scale for the colormap can be taken from another 2D-average widget to facilitate comparison. For this, first, select the Take value scale from control and select another 2D-average widget.\nAfter that, a colored line next to the color bars indicates that the two widgets are linked. The colormap donor has a continuous colored line, whereas the colormap acceptor has a dashed colored line.\nWhen the color bar sliders are changed at the donor, the acceptor changes the color scale accordingly. You can link multiple widgets together by taking the color scale of the same shared donor. You can also link multiple widgets independently, which then are marked by differently colored color lines.\nIf you want to stop sharing color scales, you can select \u0026ldquo;Release value scale\u0026rdquo; on the color scale acceptor.\n"
},
{
	"uri": "http://localhost/docs/concepts/hicognition/",
	"title": "Implementation",
	"tags": [],
	"description": "",
	"content": "Architecture overview To provide a reference implementation of the region-set focus approach, we developed HiCognition. HiCognition is a containerized web application that uses a Task-queue in conjunction with multiple workers to allow precomputation of the analysis tasks mentioned. For visualization, HiCognition draws upon powerful javascript frameworks such as D3.js and PixiJS to allow the efficient display of the pre-computed data (see the app architecture section for more details).\nData management To make managing genomic datasets for exploration practical, HiCognition contains a dataset manager that stores available datasets as well as finished pre-computations in a MySQL database. Here, the user interface of HiCognition provides a separation between genomic regions of interest and genomic features that are available for precomputation, where users can add and view datasets in an interactive table component that allows filtering and editing (see the data management section for more details).\nPreprocessing To select a region-set of interest, the user can submit preprocessing tasks using the preprocessing dialogues and get an overview of running and finished computations via the dataset viewer of the genomic regions. Once a combination of a region-set of interest and a genomic feature has finished its pre-computation, it is available for display. Here, the region-set focus approach is captured by the layout of the visualization components (see the preprocessing section for more details).\nVisualization HiCognition uses widget-collections as a container to display specific visualizations. A widget collection has a single region-set shared by all its contained widgets. Each widget inside a widget collection represents a genomic feature and provides a suitable visualization for the respective data. A widget collection can contain a variable number of widgets that can be freely arranged to adapt to a specific analysis question. Additionally, widgets of a common type can be linked to share their value-scale to facilitate quantitative comparisons across features or regions (see the widgets section for more details).\nAs genomic data frequently span multiple length scales, visualization concepts must adapt to this challenge. HiCognition solves this problem by precomputing a “resolution-stack” of a genomic region-set. Specifically, all preprocessing steps are run with different window sizes and resolutions around the regions of interest, enabling the user to rapidly explore small and large neighborhoods around the region-set of interest.\nSharing data Finally, HiCognition allows storing particular arrangements of widgets and widget collections as named sessions that can either be reused by the same user later or be shared using a static link to enable anybody to view and reuse a given analysis setup (see the data sharing section for more details).\n"
},
{
	"uri": "http://localhost/docs/development/tests/",
	"title": "Tests",
	"tags": ["development"],
	"description": "",
	"content": "All contributions to HiCognition must pass all existing tests and ideally implement new test-cases that test all aspects of new features. The tests are stratified into test for the the flask server (Backend test), tests for the front-end (Frontend tests) and integration tests that test typical user flows (Integration tests).\nBackend tests The backend tests test both the request handling of the flask server as well as the preprocessing tasks that run inside the queue worker instances. All example data has been restricted to be very compact such that the tests typically run within ~1 min. If you contribute new tests, we would ask you to abide by the same principle and not use full-length test data.\nStructure The tests are located in the back_end\\tests directory relative to the HiCognition repository. They are further structured into the following categories that reside in individual directories:\n Database models | Test the convenience methods of database model classes Delete routes | Test flask server delete routes Get routes | Test flask server get routes HiCognition package | Tests for the hicognition submodule that contains common helper functions Post routes | Test flask server post routes Tasks | Test preprocessing tasks Testfiles | Examples needed to run the tests  Within these directories, the tests are distributed to different python files that use the unittest framework to set up test cases and run them. Many of the tests need asses to a test instance of the flask app. This functionality is provided by the LoginTestCase class that can be imported from hicognition.test_helpers. If tests inherit from this class, each call to setUp will create a fresh flask app instance with an in-memory SQLite database. Be sure to call super().setUp() if you want to add other setup steps! The hicognition.test_helpers file also contains a TempDirTestCase class that can be mixed into a test case to create a temporary directory (accessible via `Te) before the test-suite and clean it up after the suite ash run.\nRunning the tests If you want to run the tests, you need a running development HiCognition instance (see the guide to find out how you can set this up). Then, you need to attach a shell to the flask-server container:\ndocker exec -it flask-server bash You can then run the entire backend suite using pytest:\ncd /code pytest . Alternatively, you can run a specific test file using python (all test files have a unit test entry point defined):\npython tests/get_routes/test_api_auth.py  If you change any code inside the hicognition package during development, you either need to rebuild the container or install the package in the running container using pip install .\n Frontend tests The frontend tests test common utility functions that are used throughout the vue.js app.\nStructure The tests are written using jest and are located in front_end\\src\\tests relative to the HiCognition repository.\nRunning the tests If you want to run the tests, you need a running development HiCognition instance (see the guide to find out how you can set this up). Then, you need to attach a shell to the node container:\ndocker exec -it node bash You can then run the entire frontend test suite using npm:\ncd /front_end npm run test Integration tests The integration tests test common user flows on a running test instance of HiCognition using cypress.\nStructure The tests are located in front_end\\e2e relative to the HiCognition repository. This directory contains both the definitions of the tests as well as a Dockerfile that defines the cypress docker image to use. The main reason we have a separate image for this is that we include a custom test initialization script (init.sh) that defines how to wait on resources needed for running the test (in this case, the flask server startup and finishing the frontend build).\nRunning the tests To run the tests, we provide an integration docker-compose file called docker_integration_tests.yml that starts the flask server in end2end mode and runs the integration tests. End2end mode means that a volatile MySql database is used (no data is persisted outside the MySql docker container), and a test-user is created at app startup. In addition, the integration test docker-compose file has a slightly different way of building the frontend files such that the file /dist/static/finished.json is deposited into the static directory after the build is finished. This file is used by the init.sh script of the cypress container to determine that the frontend build has finished.\nYou can run the integration tests as follows:\ndocker-compose -f docker_integration_tests.yml up "
},
{
	"uri": "http://localhost/docs/installation/configuration/",
	"title": "Configuration",
	"tags": [],
	"description": "",
	"content": "Configuring your HiCognition instance can be done using two approaches:\n For common setup tasks, we defined environment variables that need to be available during the start-up For more specific configuration, you can edit the flask configuration files  Environment variables Setting environment variables The most convenient way of setting your environment variables is using a .env file that specifies them as key-value pairs. docker-compose will use this file - if it is in the same directory - and inject the variables during start-up.\nNever commit a .env file for your production server to version control!\n Alternatively, you can inject the environment variables in your deploy pipeline. This is probably the cleanest approach and can be easily done with, for example, github actions.\nAvailable environment variables Production instance We expose a wide array of environment variables, some of which you don\u0026rsquo;t need to change, whereas others we highly recommend changing.\nRedefine for new instance These environment variables should be redefined if you deploy a new HiCognition instance.\n SECRET_KEY | Secret key of flask app that is used to sign the generated token DATABASE_URI | Connection string to the HiCogntion MySQL database (including username and password) MYQSL_PASSWORD | Password for MySQL database  Take from example .env file These environment variables can likely be taken from our example .env file and probably only need changing if you are deploying a custom setup.\n UPLOAD_DIR | Directory that is used to store uploaded datasets. This filepath is used inside the Docker container and should therefore be in relation to the mounted folder with code and data. CHROM_SIZES | Path to the chromosome sizes file on the server filesystem that is needed for the hicognition module. This filepath is used inside the Docker container and should therefore be in relation to the mounted folder with code and data. CHROM_ARMS | Path to the file harboring genomic locations of chromosomal arms on the server filesystem that is needed for pileups in the tasks.py file containing different background tasks. This filepath is used inside the Docker container and should therefore be in relation to the mounted folder with code and data. REDIS_URL | URL of Redis server DIR_FRONT_END | Relative path to the front_end files. DIR_STATIC | Static directory for the Nginx server MYSQL_DATA_DIR | Relative directory to persist MySQL database to INTEGRATION_TESTS | Relative path to the integration test directory DOC_PATH | Relative path to documentation files  Development instance If you are thinking about setting up a development instance of HiCognition, be sure to check out the development section.\n In the development instance, the entire HiCognition backend repository is mounted through into the flask server to facilitate hot-reload. You can specify the location of the repository using the following environment variable:\n HICOGNITION_DIR | Location of the backend part of the HiCognition repository.  This variable can be taken from our example .env file.\nFlask configuration files If you need to dive deeper into the configuration of HiCognition, you can edit the config file of the flask app (located at back_end/app/config.py relative to the HiCognition repository). This config file defines data classes for different configuration states of HiCognition:\n Config | Main config class that defines common configuration settings between all config classes DevelopmentConfig | Development config file that defines settings for flask in development mode TestingConfig | Config file for flask unittests End2EndConfig | Config file for integration tests  Be sure to rebuild the HiCognition container after you change this config file!\n Configuration variables related to server setup Note that some of the configuration variables are initialized from environment variables. So if you change them, be sure that environment variables do not override these changes!\n The following configuration variables are related to how the flask server is set up and are most likely not candidates for tuning since they refer to simple paths, flags are secrets:\n SECTRET_KEY | Secret key of flask app that is used to sign the generated token SQLALCHEMY_TRACK_MODIFICATIONS | Flag that specifies whether database modifications should be tracked UPLOAD_DIR | Directory that is used to store uploaded datasets. This filepath is used inside the Docker container and should therefore be in relation to the mounted folder with code and data. CHROM_SIZES | Path to the chromosome sizes file on the server filesystem that is needed for the hicognition module. This filepath is used inside the Docker container and should therefore be in relation to the mounted folder with code and data. CHROM_ARMS | Path to the file harboring genomic locations of chromosomal arms on the server filesystem that is needed for pileups in the tasks.py file containing different background tasks. This filepath is used inside the Docker container and should therefore be in relation to the mounted folder with code and data. REDIS_URL | URL of Redis server TESTING | Whether the server is in unittesting mode END2END | Whether the server is in integration testing mode (this is needed for setup of test users in the database)  Configuration variables related to preprocessing These configuration variables determine how preprocessing is performed and, depending on the types of tasks at hand, might be in need of adjustment.\nPREPROCESSING_MAP The PREPROCESSING_MAP configuration variable defines which types of datasets should be processed with what binsize for a given windowsize. The general structure is the following:\n{ windowsize: { datatype: [ binsize, . . . ], . . . }, . . . } The default PREPROCESSING_MAP has been chosen to provide a balance between resolution and preprocessing time. If your application requires finer resolution or different binsizes, keep in mind that small binsizes at large windowsizes can cause large loads on your server and adjustments should be made with caution.\nVARIABLE_SIZE_EXPANSION_FACTOR This floating-point number is used when preprocessing regions that have been added as interval features. It specifies how much the snippets should expand to the left and right as a fraction of the specific region.\nLeft Expansion Region Right Expansion ---------------|---------------------------------|--------------- PIPELINE_NAMES This configuration variable defines the preprocessing pipelines to be used for a given datatype. The structure of these values is:\n{ datatype: (pipeline_function, pipeline_description), . . . } The pipeline_function refers to a function in the file back_end/app/tasks.py.\nPIPELINE_QUEUES This configuration variable holds a mapping between data types and the queue it should be processed on. Currently, we define three different queues:\n short medium long  The short queues is reserved for small tasks that are not related to preprocessing. The medium queue refers to tasks that can be typically completed in less than 30s, and the long queue refers to tasks that run longer than 30s. The structure of the mapping is:\n{ datatype: queue, . . . } CLUSTER_NUMBER_LARGE and CLUSTER_NUMBER_SMALL These variables refer to the number of clusters to use when grouping regions in the embedding widgets (the 1d-feature embedding widget and 2d-feature embedding widget). The variable CLUSTER_NUMBER_LARGE is used to define small neighborhoods, and the variable CLUSTER_NUMBER_SMALL is used to define large neighborhoods (a large number of clusters means that the neighborhood they represent is smaller).\nDATASET_OPTION_MAPPING This configuration variable defines metadata options for different data types. The general structure is:\n{ \u0026#34;DatasetType\u0026#34;: { \u0026#34;bedfile\u0026#34;: { \u0026#34;ValueType\u0026#34;: { \u0026#34;ValueType1\u0026#34;: { \u0026#34;Option1\u0026#34;: [\u0026#34;Possible\u0026#34;, \u0026#34;Values\u0026#34;], . . . }, . . . } }, \u0026#34;bigwig\u0026#34;: { \u0026#34;ValueType\u0026#34;: { \u0026#34;ValueType1\u0026#34;: { \u0026#34;Option1\u0026#34;: [\u0026#34;Possible\u0026#34;, \u0026#34;Values\u0026#34;], . . . }, . . . } }, \u0026#34;cooler\u0026#34;: { \u0026#34;ValueType\u0026#34;: { \u0026#34;ValueType1\u0026#34;: { \u0026#34;Option1\u0026#34;: [\u0026#34;Possible\u0026#34;, \u0026#34;Values\u0026#34;], . . . }, . . . } }, } } Here, each dataset type can define multiple value types that can have multiple custom options. Note that changing option values only requires changing this configuration option, whereas adding value types and types of options requires changing the Dataset database model.\nSTACKUP_THRESHOLD This configuration variable defines the number of rows above which intervals are downsampled for displaying in the stacked lineprofile widget.\nOBS_EXP_PROCESSES and PILEUP_PROCESSES Defines the number of processes to use per worker to calculate observed/expected matrices and pileups, respectively.\nDocker compose files There are three different Docker compose files that allow starting HiCognition in different modes:\n docker-compose.yml | This file is used to start HiCognition in \u0026ldquo;production mode\u0026rdquo; docker_dev.yml | This file is used to start HiCognition in \u0026ldquo;development mode\u0026rdquo; docker_integration_tests.yml | This file is used to run the integration tests (see the testing section for more details)  "
},
{
	"uri": "http://localhost/docs/installation/",
	"title": "Installation",
	"tags": [],
	"description": "",
	"content": "Installation HiCognition is a containerized application and thus allows installation in a few steps. The bulk of the installation process is setting up the configuration environment variables.\nRequirements This chapter briefly outlines the minimum software and hardware requirements to run the HiCognition server. To use HiCogntion all you need as Device with a Chrome Browser\nBuild HiCognition HiCognition is fully containerized in Docker and orchestrated by Docker compose. This chapter shows you the three simple steps you need to do to run your own HiCognition server on your system.\nConfiguration How to tailer your HiCognition server to your needs is discribed in this section.\nUpdating Since HiCognition is still actively developed, this section shows you the few steps you need to take to have the newest and shiniest version of HiCognition.\n"
},
{
	"uri": "http://localhost/docs/widgets/stackup/",
	"title": "Stacked lineprofiles",
	"tags": ["widgets", "1D-features"],
	"description": "",
	"content": "The stacked line profile widget can be used to display individual examples of 1D-genomic features over a specific region set. It is a heatmap representation, where each row corresponds to one genomic region.\nThe stacked line profile widget does not show the entirety of the selected region-set, but only a subset. The down-sampling ratio can be defined as configuration variable (see the configuration section for details)\n Suitable data The stacked line profile widget is suitable for any genomic dataset that can be represented using a bigwig file. This includes coverage tracks for Chip-seq experiments, Gro-seq experiments, but also features derived from Hi-C data such as insulation scores.\nPreprocessing algorithm The preprocessing algorithms are very similar to the ones used in the 1D-average widget\nPoint-regions Snippets are extracted from the respective bigwig file for each entry in the genomic region set, with different window sizes during the preprocessing stage. These snippets are then stacked row-wise into a matrix.\nInterval-regions Snippets are extracted from the respective bigwig file for each entry in the genomic region set during the preprocessing stage. In contrast to the point-region preprocessing, the snippets are defined by each region\u0026rsquo;s start and end. Before stacking, each snippet is scaled to have the same number of bins.\nVisualization The stacked line profile widget displays aggregated data sets as a heatmap. The color scale used to display the values is dynamic and can be adjusted with the sliders at the top and bottom of the color bar.\nWidget controls The stacked line profile widget defines two widget controls, one for specifying the sort order of the rows and the other for sharing value scales between widgets.\nSort order The sort order widget control option specifies which values to sort and whether to sort in an ascending or descending fashion.\nFor point-regions, the sort values are the following:\n Center column | sort by the center column Random | shuffle rows  For interval regions, the sort values are the following:\n Region | sort by the average value of the continued region (between start and end) Left boundary | sort by left boundary Right boundary | sort by right boundary Random | shuffle rows  Sharing The stacked line profile widget supports sharing value scales in a similar fashion to the 2d-average widget. In addition, the stacked line profile widget allows sharing sort-order between widgets that reside in the same widget collection. For this, click on \u0026ldquo;Take sort order from\u0026rdquo; then click on the target widget.\nAfter that, a colored line under the stacked line profile indicates that the two widgets are linked. The sort order donor has a continuous colored line, whereas the sort order acceptor has a dashed colored line.\nThe sort order acceptance widgets can now no longer change their sort orders, and their sort order is set to share.\nWhen the sort order is changed on the donor widget, however, all acceptor widgets follow the suite. You can link multiple widgets together by taking the sort order of a shared donor. You can also link multiple widgets independently, which are then marked by differently colored color lines.\nIf you want to stop sharing sort orders, you can select \u0026ldquo;Release sort order\u0026rdquo; on the sort order acceptor.\n"
},
{
	"uri": "http://localhost/docs/installation/updating/",
	"title": "Updating",
	"tags": [],
	"description": "",
	"content": "Updating HiCognition is relatively easy since all changes to the code can be integrated by rebuilding the containers. Since we use automatic database migration tools, all changes to the MySQL database are applied automatically. The only exception would change that breaks compatibility with older, cached preprocessing data. But these exceptions will be communicated with the newest release and contain a detailed guide on the migrate old versions to new ones.\nGet the new version To get the newest HiCognition version (or any version you would like to run), first, stop any running HiCognition instance via\ncd HiCognition docker-compose down Where HiCognition refers to the location of the cloned HiCognition GitHub repository, then get the latest version using git:\ngit fetch --all git checkout master # or any other branch you would like to use git pull # assuming this is not a new branch Rebuild containers We are currently in the process of migrating all containers to Docker Hub. Once this is done, you can then just pull the relevant images from there. Stay tuned!\n In order to integrate all code changes into your local containers, you need to rebuild them via:\ndocker-compose build You should expect this process to take 5-10 min.\nRestart HiCognition After you have downloaded the newest version of HiCognition and rebuilt the containers, you can restart HiCognition using:\ndocker-compose up -d This will apply all database migrations to the MySQL database and start the new versions of all dependent containers. After startup, HiCognition is read to be used!\n"
},
{
	"uri": "http://localhost/docs/data_management/",
	"title": "Data management",
	"tags": [],
	"description": "",
	"content": "Data management HiCognition is an implementation of the region-set focus approach. One central aspect of the application is to allow the management of datasets, both representing genomic regions and features. For more complex analyses, HiCognition also implements managing collections of datasets.\nGenomic regions This chapter describes genomic regions are the central element region-set focus approach in more detail.\nGenomic features Genomic features are mainly used to understand genomic regions in the region-set focus approach. They can thus be thought of as “independent variables” that explain the “dependent” genomic regions.\nCollections HiCognition uses collections to group datasets together for them to be available for some of the more complex processing algorithms.\nGenome assemblies HiCognition allows managing genome assemblies to work with different assemblies and organisms in parallel. This chapter describes how this is done.\n"
},
{
	"uri": "http://localhost/docs/widgets/1d_feature_embedding/",
	"title": "1D-feature embedding",
	"tags": ["widgets", "1D-features"],
	"description": "",
	"content": "The 1D-feature embedding widget can be used to display the distribution of genomic regions with regards to a collection (see here for more details on collections) of 1D features. It represents a 2-dimensional embedding of the genomic regions as a heatmap of points.\nSuitable data The 1D-feature embedding widget is suitable for a collection of 1D features. 1D-features are any genomic dataset that can be represented using a bigwig file. This includes coverage tracks for Chip-seq experiments, Gro-seq experiments, but also features derived from Hi-C data such as insulation scores.\nPreprocessing algorithm Point-regions During the preprocessing stage, the value of each 1D-feature at each region (+/- the respective binsize) is extracted and stacked into a feature matrix as follows:\n    Feature 1 \u0026hellip; Feature k     Genomic region 1 0.1 \u0026hellip; 1.5   \u0026hellip; \u0026hellip; \u0026hellip; \u0026hellip;   Genomic region n 0.8 \u0026hellip; 0.4    Where k refers to the number of features in the respective 1D-feature collection and n refers to the number of genomic regions in the respective region set. Following this step, umap is used with default parameters to get a 2-dimensional embedding of the genomic regions.\nAdditionally, the regions are clustered using k-means clustering into two different cluster-sets (one with a high number of clusters and one with a low number of clusters; see the configuration section on how to change these numbers). The average magnitude of all features within each cluster is saved and then used to display information thumbnails (see the visualization section for more details).\nInterval-regions Interval features are treated exactly as point features, except that instead of the value at the region, the average value over the region defined by the start and end is taken.\nVisualization The distribution of the genomic regions with regards to a collection of 1D-features is visualized as a 2D-histogram, with the density of points being displayed using a colormap. This widget defines a tooltip that, when hovered over the points, will display the feature distribution for the highlighted cluster.\nThe highlighted clusters are defined as described above, and the bar plot of the features defines the standardized feature values (0 mean and unit variance), with positive values being marked red and negative values being marked blue.\nThe underlying 1D features can also be visualized by overlaying the respective values using the overlay controls (see below). Here, the colormap is switched to represent the selected feature value.\nWidget controls The 1D-feature embedding widget defines two controls on the widget and one control on the bar chart tooltip.\nOverlay The overlay controls allow choosing a feature from the underlying 1D-feature collection to overlay over the heatmap. To avoid mixing density and overlay magnitude, the average value of the overlayed feature is displayed for each bin. In addition, the default density overlay can also be selected here.\nNeighborhood size One can use the neighborhood size option to choose whether to display large or small clusters (for defining the respective sizes, see the configuration section) in the barplot tooltip.\nCreate new regions If one of the highlighted clusters is interesting and you want to explore them further, you can create a new genomic region set representing the highlighted regions. For this, when the barplot tooltip is shown, click on the \u0026ldquo;Create new region\u0026rdquo; button will appear. After clicking that button, a dialog pops up that lets you define the name for your new region set.\n"
},
{
	"uri": "http://localhost/docs/development/cont_guide/",
	"title": "Contribution guide",
	"tags": ["development"],
	"description": "",
	"content": "HiCognition is an open-source project, and as such, we welcome all contributions to our codebase. The main requirement for a contribution to be accepted is that it passes all tests (described in detail here) and conforms to our style decisions.\nAutomatic testing When a pull request is issued on the HiCognition GitHub repository, we have set up git actions that check the code for linting issues, run it against formatting guidelines, and dispatch our testing suite. This means that, in principle, you don\u0026rsquo;t need to set up local testing, although we highly recommend doing so to decrease frustration (see our testing guide to learn how to set up local testing.).\nFormatting guidelines We use black for code formatting to have a consistent way our python code looks. The automatic actions will run\nblack --check . against your code, so we recommend using black for python code formatting beforehand.\nLinting We use pylint to check code for linting issues using the following command:\npylint --disable=C0330 --fail-under=8 app/ Documentation guidelines Every function/class should have docstrings according to the rules laid out in PEP257:\n Multi-line docstrings consist of a summary line just like a one-line docstring, followed by a blank line, followed by a more elaborate description. The summary line may be used by automatic indexing tools; it is important that it fits on one line and is separated from the rest of the docstring by a blank line. The summary line may be on the same line as the opening quotes or on the next line. The entire docstring is indented the same as the quotes at its first line (see example below).\n "
},
{
	"uri": "http://localhost/docs/preprocessing/",
	"title": "Preprocessing",
	"tags": [],
	"description": "",
	"content": "Preprocessing HiCognition is a visual exploration tool that allows users to explore the aggregate behavior of genomic features (see the concepts section for more detail). This means that this aggregate behavior needs to be computed for a given genomic region and genomic feature combination. Therefore, HiCognition provides both a job queue that runs the preprocessing (see the architecture section for more details on this) and a user interface to submit jobs and check their status.\nPreprocessing tasks The section described the different types of preprocessing steps HiCognition performs in the background to explore the genomic data via the widgets in real-time.\nManage preprocessing This chapter describes the user interface to submit preprocessing tasks and check their progress.\n"
},
{
	"uri": "http://localhost/docs/widgets/2d_feature_embedding/",
	"title": "2D-feature embedding",
	"tags": ["widgets", "2D-features"],
	"description": "",
	"content": "The 2D-feature embedding widget can be used to display the distribution of genomic regions regarding a 2D-genomic feature. It represents a 2-dimensional embedding of the genomic regions as a heatmap of points.\nSuitable data The 2D-feature embedding widget is suitable for any genomic dataset that can be represented using a multiresolution cooler file. This is mostly suitable for Hi-C data but can include other data sets that assign a value to a tuple of genomic coordinates.\nPreprocessing algorithm In general, the preprocessing for data to be displayed in the 2D-feature embedding widget happens together with preprocessing for the 2D-average widget, and thus many of the steps are shared.\nPoint-regions During the preprocessing state, snippets of the underlying interaction matrix are extracted from the mcool file for each entry in the genomic region set, with different window sizes. Then, these images are downsampled and flattened into a \u0026ldquo;feature representation\u0026rdquo;. The resulting feature matrix has the following shape:\n    Image feature 1 \u0026hellip; Image feature k     Genomic region 1 0.1 \u0026hellip; 1.5   \u0026hellip; \u0026hellip; \u0026hellip; \u0026hellip;   Genomic region n 0.8 \u0026hellip; 0.4    Where k refers to the number of pixels in the downsampled images and n refers to the number of genomic regions in the respective region set. Following this step, umap is used with default parameters to get a 2-dimensional embedding of the genomic regions.\nAdditionally, the regions are clustered using k-means clustering into two different cluster-sets (one with a high number of clusters and one with a low number of clusters; see the configuration section on how to change these numbers). A cluster \u0026ldquo;thumbnail\u0026rdquo; that represents the average image within this cluster is saved and then used to display information thumbnails (see the visualization section for more details).\nInterval-regions Interval features are treated exactly as point features, except that images are scaled to a common size before processing.\nVisualization The distribution of the genomic regions regarding a 2D feature is visualized as a 2D-histogram, with the density of points being displayed using a colormap. This widget defines a tooltip that will display a cluster thumbnail that represents the average image within that cluster when hovered over the points.\nWidget controls The 2D-feature embedding widget defines four controls on the widget and one control on the thumbnail tooltip.\nSharing The sharing controls allow you to select whether all thumbnail representations should share a common color scale or not.\nScale The scale widget control allows to switch between ICCF values (I teratively C orrected C ontact F requency) and Observer/expected values, which were normalized to the genome-wide distance-dependent decay of contact frequency.\nTransform The transform widget control allows you to select whether the values displayed in the thumbnails should be log-transformed or not.\nNeighborhood size One can use the neighborhood size option to choose whether to display large or small clusters (for defining the respective sizes, see the configuration section) in the thumbnail tooltip.\nCreate new region If one of the highlighted clusters is interesting and you want to explore them further, you can create a new genomic region set representing the highlighted regions. For this, when the thumbnail tooltip is shown, click, and the \u0026ldquo;Create new region\u0026rdquo; button will appear. After clicking that button, a dialog pops up that lets you define the name for your new region set.\n"
},
{
	"uri": "http://localhost/docs/widgets/",
	"title": "Widgets",
	"tags": [],
	"description": "",
	"content": "Widgets HiCognition implements the region-set focus approach (see the concept section for details) on a visualization level using widget collections and widgets. Widget collections represent a single set of genomic regions (e.g., Chip-Seq peaks of a target protein) and host one or more widgets representing genomic features (e.g., Chip-Seq tracks or Hi-C tracks).\nFeatures are linked to genomic regions via preprocessing steps (see the preprocessing section for more details), which primarily represent data aggregation. Once preprocessing has linked features to genomic regions, they are available for addition to a widget collection via appropriate widgets (see the widget controls section on how to do that).\nHiCognition implements preprocessing to allow answering three main questions at a genomic region set (see the concept section for more details):\n Exploring average behavior: What is the average magnitude of a specific 1d-/2d-genomic signal? Exploring heterogeneity: Is the population of regions homogeneous with respect to a collection of 1d- or 2d-features? What subsets have different behavior with respect to a collection of 1d- or 2d-features? Enrichment analysis: What other regions are enriched?  The results of these preprocessing steps can be visualized using specific widgets:\n1D-average widget Allows to assess what the average magnitude of a 1d-genomic signal is at a genomic region set\n2D-average widget Allows to assess what the average magnitude of a 2d-genomic signal is at a genomic region set\nStacked lineprofile widget Allows to assess whether a population of regions is homogeneous with regards to a 1d-genomic signal\n1D-feature embedding widget Allows to assess whether a population of regions is homogeneous with regards to a set of 1d-genomic signals\n2D-feature embedding widget Allows to assess whether a population of regions is homogeneous with regards to a 2d-genomic signal\nAssociation widget Allows to assess what other regions overlap with a set of genomic regions\n"
},
{
	"uri": "http://localhost/docs/widgets/association/",
	"title": "Association",
	"tags": ["widgets", "enrichment"],
	"description": "",
	"content": "The association widget allows you to determine what other genomic regions are enriched at your target genomic region set. It contains two visualizations that give you an overview of where the most enrichment happens (upper plot) and what is enriched at those sites (lower plot).\nSuitable data The association widget is suitable for a collection of genomic regions (see here for more information about collections).\nPreprocessing algorithm Point-regions During the preprocessing stage, the LOLA algorithm is run for each bin along the specific windowsize. This means that a contingency table is built for each bin and candidate region that represents the overlap of the query region (the selected region set), a suitable universe, and a candidate target region (one entry in the region collection).\nSheffield et al. 2016\nIn this preprocessing step, the universe is defined to be all bins of the selected binsize along the entire genome.\nInterval-regions Preprocessing for interval regions works the same as for point-regions except that the query bins have different sizes, and the universe is the union of all query regions.\nThe particular selection of the enrichment universe for interval-regions means that enrichment is relative to the selected region-sets! This means that uniform enrichments across all selected regions may be lower in magnitude.\n Visualization The association widget consists of two main visualizations, the enrichment overview at the top and the ranked enrichments at the bottom. The enrichment overview represents the maximum enrichment at that particular genomic bin amongst all regions in the region-set. It can be thought of as a measure of how much the respective collection exhibits enrichment.\nThe overview widget is simultaneously a control point since it allows the data selection to show in the rank plot below. Here, the currently selected bin is highlighted in red, and clicking on other bars shifts the selection. The rank-plot below shows the odds ratio of the respective members of the selected region collection ranked from lowest to highest. If you hover over one of the points, the name of the respective region set is displayed.\n"
},
{
	"uri": "http://localhost/docs/sessions/",
	"title": "Data sharing",
	"tags": [],
	"description": "",
	"content": "Data sharing HiCognition allows users to share their analysis workflows through persisting them in analysis sessions. These sessions can be saved, restored, and shared through persistent links with others.\nSessions This chapter will explain the HiCognition sessions that encapsulate a particular configuration of widgets inside all open widgets in more detail.\n"
},
{
	"uri": "http://localhost/docs/development/",
	"title": "Development",
	"tags": [],
	"description": "",
	"content": "Development information This page contains information about how HiCognition is structured and should be a starting point for people who consider contributing to HiCognition.\nApp architecture This chapter contains a description of the architecture of HiCognition in more detail.\nDevelopment environment This chapter describes how to set up a local development environment.\nTests All contributions to HiCognition must pass all existing tests and ideally implement new test cases that test all aspects of new features. The types of tests a contribution must pass are described here in more detail.\nContribution guide HiCognition is an open-source project, and as such, we welcome all contributions to our codebase. In this chapter, we will outline our style decisions.\nBefore contributing, we recommend that you read the contribution guide\n "
},
{
	"uri": "http://localhost/docs/",
	"title": "",
	"tags": [],
	"description": "",
	"content": "HiCognition A visual exploration and hypothesis testing tool for 3D genomics HiCognition is a data exploration tool that allows stream-lined exploration of aggregate genomic data. HiCognition is centered around Hi-C data but also enables integration of Chip-seq and region-based data.\n"
},
{
	"uri": "http://localhost/docs/sessions/session/",
	"title": "Session",
	"tags": [],
	"description": "",
	"content": "HiCognition sessions encapsulate a particular configuration of widgets inside all open widgets.\nCreating a session To save the current state of all your widget collections, click on Save Session in the top-right menu:\nThis will open a dialogue, which allows you to name your current session:\nWhen you click submit, this will persist your session in the database.\nRestoring sessions After you create a session, you can restore your session by clicking on the My Session button in the top-right menu. This will open a dialogue that shows all your available sessions. Here, you can click on a particular session, which then shows the context options. Amongst these, you can click on Restore, which will restore the saved session.\nRestoring a session with delete your current workspace configuration!\n Sharing a session with others To share a session with other users of HiCognition, you can click on Get Url in the session table. This will show a URL with a unique token for this session:\nWhen a user of HiCognition visits this URL, the session will be automatically restored.\nIf you share a particular dataset using a session, other users will have access to it!\n "
},
{
	"uri": "http://localhost/docs/data_management/genome_assemblies/",
	"title": "Genome assemblies",
	"tags": [],
	"description": "",
	"content": "HiCognition allows managing genome assemblies to be able to work with different assemblies and organisms in parallel.\nAdding genome assemblies To add a genome assembly click the Add Genome Assembly button in the data management drawer:\nThis will open a dialogue that lets you define a new genome assembly:\nHere you need to give your assembly a name (this needs to be unique), select the corresponding organism, and upload a file specifying the sizes of the chromosomes and the chromosomal arms. The chromosome sizes file needs to define the name, start, and end of each chromosome and use a tab-separator:\nChromosome sizes\nchr1 0 1000000 . . . . . . . . . The chromosome arms file needs to define the chromosomal arms also with name, start and end and use a tab-separator:\nChromosome arms\nchrom start end chr1 0 125200000 chr1 125200000 249250621 . . . . . . . . . Here, the two arms are written in separate rows with the same chromosome name as an identifier.\nManaging genome assemblies You can view your genome assemblies by clicking the Show Genomes button in the data management drawer:\nThis will open a dialogue that lets you view all available genome assemblies:\nHere, you can look at all the genomes and check how many datasets depend on them.\nIf you want to delete a genome, first delete all dependent datasets, then you can delete it from the genome table.\n "
},
{
	"uri": "http://localhost/docs/tags/enrichment/",
	"title": "enrichment",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://localhost/docs/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://localhost/docs/tags/widgets/",
	"title": "widgets",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://localhost/docs/tags/2d-features/",
	"title": "2D-features",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://localhost/docs/tags/1d-features/",
	"title": "1D-features",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://localhost/docs/tags/development/",
	"title": "development",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://localhost/docs/getting_started/get_started_w_example_data/",
	"title": "Quick start with example data",
	"tags": [],
	"description": "",
	"content": "Quick start with example data To take your first steps with HiCognition, you can download example data from our dropbox location. The files located there are centered on analysis connected to sister chromatid sensitive Hi-C.\nExample 1: Conformation of sister chromatids around TADs Needed data:\n G2_tads_w_size.bed | The location of TADs in G2 synchronized HeLa cells G2.fc_1_2_3_4.wOldG2.cis.1000.mcool | Cis-sister contacts in G2 synchronized HeLa cells G2.fc_1_2_3_4.wOldG2.trans.1000.mcool | Trans-sister contacts in G2 synchronized HeLa cells  To upload the files, follow our upload instructions for genomic regions and genomic features. The metadata settings are the following:\nTADs:\n Perturbation | none Cell cycle stage | G2 Genome assembly | hg19 Sizetype | Interval ValueType | Derived Method | HiC  Cooler files:\n Perturbation | none Cell cycle stage | G2 Genome assembly | hg19 ValueType | Interaction Method | HiC Normalization | ICCF  The .mcool files are quite big, and you should expect them to take a few minutes to upload (depending on your internet connection).\n Once the files are uploaded, start preprocessing the two 2D features at TAD-boundaries by following our preprocessing guide. Once preprocessing is finished, you can create a widget collection by clicking on the at the bottom right of the HiCognition start page. This will create an empty widget collection:\nBy clicking on the region-controls, you can select your TADs as a region. Once that is done, hover over the center +-icon to reveal the widget-type menu:\nOnce you select the 2D-average widget, you can select one of the two 2D features you added. For example, if you select the cis-sister contacts, your widget collection should look like this:\nThis picture represents the average behavior of cis-sister contacts around TADs. You can then resize your widget collection to add trans-sister contacts as a second widget. The resulting collection should look like this:\nThis view now represents the average behavior of cis-sister and trans-sister contacts around TAD-boundaries. If you want to look at the heterogeneity of, e.g., trans-sister contacts around TADs, you can expand the size of your widget collection to add a new slot and fill it with a 2D-embedding widget:\nOnce you have added the widget, you can select the trans-sister contacts as features to display. Your widget collection should now look like this:\nThe 2D-embedding widget now allows you to look at the heterogeneity of trans-sister contacts at TADs (see the section about this widget for more details).\n"
},
{
	"uri": "http://localhost/docs/tags/architecture/",
	"title": "architecture",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://localhost/docs/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
}]